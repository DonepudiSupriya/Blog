{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMQKj3waEksqE/FGk1XfdO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonepudiSupriya/Blog/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qxsAxoITvMl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PYTORCH**\n",
        "#Linear\n",
        "\n",
        "nn stands forneural network\n",
        "1.pytorch uses tensor\n",
        "Tensor is simimlar to multidimentional array\n",
        "2.PYTHOR IS object oriented\n",
        "\n",
        "propogate the input to the predictions\n",
        "\n",
        " 1. Make prediction 2.calculate the loss\n",
        " 3.Back propagation-- 4.gradient of the loss function will be calculated\n",
        " 4.optimization - updates the weights(multiply the inputs with the new weights)\n",
        " 5.Repeat\n",
        " diff b\\w optimization an backpropagation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mi_xZkjHvOSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "j3x2MKJnvQoh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 1 : LOAD DATASET\n"
      ],
      "metadata": {
        "id": "k2wBbtCTwFSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.randn(1000,10)\n",
        "y=torch.randn(1000,1)\n",
        "print(type(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aaoz6EB1wDIc",
        "outputId": "7378a886-2a66-4f4b-bbbb-171dd25c316c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILD THE ARCHITECTUTRE\n",
        "\n",
        "let us bulid a network with three layers.\n",
        "first layer contains 100 neurons\n",
        "second layer contains 50 neurons\n",
        "output(third )layer consists 1 neuron"
      ],
      "metadata": {
        "id": "vweimM83xOp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SampleNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SampleNet,self).__init__()\n",
        "    self.fc1=nn.Linear(10,100)\n",
        "    self.fc2=nn.Linear(100,50)\n",
        "    self.fc3=nn.Linear(50,1)\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "epYmUgFHwLtj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=SampleNet()\n",
        "criterion=nn.MSELoss()\n",
        "optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8AsavQLY2zzS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  predictions = model(X)\n",
        "  loss=criterion(predictions,y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  print(f\"epoch {epoch+1}-loss:{loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_41BrqRM32IS",
        "outputId": "9df3f92f-25df-460f-efee-75df95206f88"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1-loss:0.9889442324638367\n",
            "epoch 2-loss:0.9834457635879517\n",
            "epoch 3-loss:0.9786376953125\n",
            "epoch 4-loss:0.9742775559425354\n",
            "epoch 5-loss:0.9703845381736755\n",
            "epoch 6-loss:0.9668927192687988\n",
            "epoch 7-loss:0.963670551776886\n",
            "epoch 8-loss:0.9607703685760498\n",
            "epoch 9-loss:0.958081066608429\n",
            "epoch 10-loss:0.955476701259613\n",
            "epoch 11-loss:0.9529514312744141\n",
            "epoch 12-loss:0.9504851698875427\n",
            "epoch 13-loss:0.9480305314064026\n",
            "epoch 14-loss:0.9456505179405212\n",
            "epoch 15-loss:0.9433055520057678\n",
            "epoch 16-loss:0.9409732818603516\n",
            "epoch 17-loss:0.9386861324310303\n",
            "epoch 18-loss:0.9364299178123474\n",
            "epoch 19-loss:0.9341914057731628\n",
            "epoch 20-loss:0.9318950176239014\n",
            "epoch 21-loss:0.9295113682746887\n",
            "epoch 22-loss:0.9270470142364502\n",
            "epoch 23-loss:0.9245173335075378\n",
            "epoch 24-loss:0.9219330549240112\n",
            "epoch 25-loss:0.9193027019500732\n",
            "epoch 26-loss:0.916668713092804\n",
            "epoch 27-loss:0.9140066504478455\n",
            "epoch 28-loss:0.9113327264785767\n",
            "epoch 29-loss:0.9085897207260132\n",
            "epoch 30-loss:0.9057708978652954\n",
            "epoch 31-loss:0.9028608202934265\n",
            "epoch 32-loss:0.899880588054657\n",
            "epoch 33-loss:0.8968923091888428\n",
            "epoch 34-loss:0.8938660621643066\n",
            "epoch 35-loss:0.8908121585845947\n",
            "epoch 36-loss:0.8876803517341614\n",
            "epoch 37-loss:0.8844793438911438\n",
            "epoch 38-loss:0.8812536001205444\n",
            "epoch 39-loss:0.8779774308204651\n",
            "epoch 40-loss:0.8746734261512756\n",
            "epoch 41-loss:0.8713295459747314\n",
            "epoch 42-loss:0.8679215312004089\n",
            "epoch 43-loss:0.8644246459007263\n",
            "epoch 44-loss:0.8608746528625488\n",
            "epoch 45-loss:0.8572903871536255\n",
            "epoch 46-loss:0.8536789417266846\n",
            "epoch 47-loss:0.8500261902809143\n",
            "epoch 48-loss:0.8463302254676819\n",
            "epoch 49-loss:0.8425967693328857\n",
            "epoch 50-loss:0.8388046622276306\n",
            "epoch 51-loss:0.8349935412406921\n",
            "epoch 52-loss:0.8311498761177063\n",
            "epoch 53-loss:0.8272680044174194\n",
            "epoch 54-loss:0.8233637809753418\n",
            "epoch 55-loss:0.8194178342819214\n",
            "epoch 56-loss:0.8154422044754028\n",
            "epoch 57-loss:0.8114364743232727\n",
            "epoch 58-loss:0.8073598742485046\n",
            "epoch 59-loss:0.8032351732254028\n",
            "epoch 60-loss:0.7990425229072571\n",
            "epoch 61-loss:0.7948428988456726\n",
            "epoch 62-loss:0.7905864119529724\n",
            "epoch 63-loss:0.786281943321228\n",
            "epoch 64-loss:0.7819334864616394\n",
            "epoch 65-loss:0.777523934841156\n",
            "epoch 66-loss:0.7730867266654968\n",
            "epoch 67-loss:0.768598735332489\n",
            "epoch 68-loss:0.7640661597251892\n",
            "epoch 69-loss:0.7594689726829529\n",
            "epoch 70-loss:0.7548314332962036\n",
            "epoch 71-loss:0.7501654028892517\n",
            "epoch 72-loss:0.7454744577407837\n",
            "epoch 73-loss:0.7407550811767578\n",
            "epoch 74-loss:0.7359871864318848\n",
            "epoch 75-loss:0.7311599254608154\n",
            "epoch 76-loss:0.7262871265411377\n",
            "epoch 77-loss:0.7213531136512756\n",
            "epoch 78-loss:0.7163667678833008\n",
            "epoch 79-loss:0.7113539576530457\n",
            "epoch 80-loss:0.706261157989502\n",
            "epoch 81-loss:0.701145589351654\n",
            "epoch 82-loss:0.6960229277610779\n",
            "epoch 83-loss:0.6908561587333679\n",
            "epoch 84-loss:0.6856265664100647\n",
            "epoch 85-loss:0.680395245552063\n",
            "epoch 86-loss:0.6751009225845337\n",
            "epoch 87-loss:0.6697490215301514\n",
            "epoch 88-loss:0.6643912196159363\n",
            "epoch 89-loss:0.6590012907981873\n",
            "epoch 90-loss:0.653562605381012\n",
            "epoch 91-loss:0.6480681300163269\n",
            "epoch 92-loss:0.6425282955169678\n",
            "epoch 93-loss:0.6369875073432922\n",
            "epoch 94-loss:0.6314056515693665\n",
            "epoch 95-loss:0.6257601380348206\n",
            "epoch 96-loss:0.6200916171073914\n",
            "epoch 97-loss:0.6144187450408936\n",
            "epoch 98-loss:0.6087163090705872\n",
            "epoch 99-loss:0.6030085682868958\n",
            "epoch 100-loss:0.5972732901573181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uc-D3m7yNGfE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mDz4nRRNDKe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}